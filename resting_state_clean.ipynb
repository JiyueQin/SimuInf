{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968b87c4-7c16-4b9d-9b8e-c76617045d47",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "From previous 2D simulations of different bootstrap methods to construct SCB, we saw that the nonparametric bootstrap with Radmacher multipliers and t-standardization is the best. This is true in Gaussian noise setting and the t3 noise setting. However, the fMRI data may not follow Gaussian or t3. \n",
    "\n",
    "Here, we perfrom resting-state validation to the bootstrap method and the inverse set method. \n",
    "\n",
    "\n",
    "\n",
    "**Data**\n",
    "\n",
    "We used resting-state data from 1,000 Functional Connectomes Project. \n",
    "\n",
    "**First-level Analysis**\n",
    "\n",
    "In FSL, a first-level analysis has been conducted independently for each subject. \n",
    "\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857392c-7746-4b24-8fcd-e4db0ed2f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "import matplotlib.pyplot as plt \n",
    "import SimuInf\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import Normalize\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import scipy.stats\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "#import sanssouci as ss\n",
    "\n",
    "import pyperm as pr\n",
    "from nilearn.plotting import plot_img, plot_stat_map, view_img\n",
    "from nilearn.image import get_data, load_img, new_img_like"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f09f2f9e-b8aa-47f4-8f6a-861dd69838f5",
   "metadata": {},
   "source": [
    "# Data Import \n",
    "\n",
    "Now we read the data, which were previously downloaded into the folder from FSL folder in http://tinyurl.com/clusterfailure\n",
    "\n",
    "We use the Beiging.zip dataset since it has the most particiants, which will reduce dependence between resampled sub-samples. The folder has contrast maps from 198 subjects under various task paradim and smoothing parameters. Here, we use boxcar10_smoothing_4mm, where boxcar10 means the block activity with 10-s on-off. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98d7f5-df52-464a-a0e0-3986c4b24605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data directory\n",
    "data_dir = os.path.join(os.getcwd(),'data')\n",
    "beijing_data_dir = os.path.join(os.getcwd(),'data','Beijing')\n",
    "bold_files_total =  os.listdir(beijing_data_dir)\n",
    "print('# of total files in the folder (various settings):', len(bold_files_total))\n",
    "bold_files = [os.path.join(beijing_data_dir, file) for file in bold_files_total if 'boxcar10_smoothing_4mm' in file]\n",
    "print('# of subjects in Beijing dataset(one setting):', len(bold_files))\n",
    "print(bold_files[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3b474-7bb6-4c5f-a8c3-88cbbfa45c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bold_files1 = [os.path.join(beijing_data_dir, file) for file in bold_files_total if 'Event3_smoothing_4mm' in file]\n",
    "print('# of subjects in Beijing dataset(one setting):', len(bold_files1))\n",
    "print(bold_files1[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92b29e-506e-4f6e-8393-79dfbe574276",
   "metadata": {},
   "outputs": [],
   "source": [
    "## raw constrat image from the first subject \n",
    "plot_img(bold_files[0], colorbar = True)\n",
    "plot_stat_map(bold_files[0], colorbar=True)\n",
    "print(\"the shape of the first bold file:\", get_data(bold_files[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf5841-da58-484f-8680-58e7376b6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## raw constrat image from the first subject \n",
    "plot_img(bold_files1[0], colorbar = True)\n",
    "#plot_stat_map(bold_files1[0], colorbar=True)\n",
    "print(\"the shape of the first bold file:\", get_data(bold_files1[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c45147-d286-4668-b331-553a6f0301d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(get_data(bold_files[0]).flatten(), bins=200, density = False)\n",
    "plt.show()\n",
    "np.sum(get_data(bold_files[0])==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e605e-2a76-400e-b768-33831e8dfb15",
   "metadata": {},
   "source": [
    "First we apply the mask, which will reduce the image size and focus only on areas in the brain and apply some smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a71c55-b98e-4887-8aff-6fc6adfbe16d",
   "metadata": {},
   "source": [
    "Here we use the MNI mask, which is of shape (91, 109, 91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a28b85-bc22-4a6c-8fef-526e6e24e6c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = data_dir + '\\\\MNImask.nii' #MNI mask \n",
    "plot_img(mask)\n",
    "print(\"the shape of the MNI mask:\", get_data(mask).shape)\n",
    "print(\"number of voxels inside the MNI mask\", np.sum(get_data(mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa24a1-07e8-42b7-9816-5552bb1abb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_data = get_data(bold_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4a7bd-ebdc-4afa-89a4-8bf7c7a9319f",
   "metadata": {},
   "source": [
    "In a contrast map, if the voxel is exactly 0, then that is outside of the mask. Each subject's brain is different so the mask should be different. Here, we apply a stricter mask, which is the intersection of each individual's mask in our sample. That is, any voxel with at least one zero will be excluded. If the mask is too big, then for some voxels, the majority of the voxels are 0 and the sd will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72750885-c10d-4c1f-884c-d219dc49b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_data1 = get_data(bold_files1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b302c-4a78-4106-9ca3-7bbbac57a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask, which is the intersection of the voxels inside brain among all people\n",
    "# this mask is smaller than the MNI mask\n",
    "print(bold_data.shape)\n",
    "mask1 = np.all(bold_data, -1)*1\n",
    "print(mask1.shape)\n",
    "print('number of voxels in the self-created mask:', np.sum(mask1))\n",
    "\n",
    "# covert the np array into Nifti1Image\n",
    "mask1_img = new_img_like(mask, mask1)\n",
    "print(type(mask1_img))\n",
    "plot_img(mask1_img, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a125f3-b312-485a-94f1-af93dcb27c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection with the MNI mask: self-created one does not have those holes because the in first-level analysis, the mask they used does not have holes\n",
    "# there will be always signal and those 0s are manually put based on a mask\n",
    "mask_final = np.all(np.array([get_data(mask), mask1]), 0)\n",
    "print(mask_final.shape)\n",
    "print('number of voxels in the final mask:', np.sum(mask_final))\n",
    "\n",
    "# covert the np array into Nifti1Image\n",
    "mask_final_img = new_img_like(mask, mask_final)\n",
    "plot_img(mask_final_img, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5c814-c391-4d93-82c6-51ae599714d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_final1  = np.all(np.array([get_data(mask), np.all(bold_data1, -1)*1]), 0)\n",
    "print(mask_final1.shape)\n",
    "print('number of voxels in the final mask:', np.sum(mask_final1))\n",
    "mask_final_img1 = new_img_like(mask, mask_final1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac413c3-0f6b-46ba-9e79-201a508f3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "# no additional smotthing since contrast maps were already smoothed\n",
    "fwhm = 0 # Set the smoothness parameter (in mm)\n",
    "# this creates a NiftiMasker class, if mask_img is not prvided, will compute the mask in the fit step\n",
    "# mask_img needs to be Niimg-like object so it cannot be the array.# rerun!\n",
    "masker = NiftiMasker(smoothing_fwhm=fwhm, mask_img=mask_final_img).fit()\n",
    "data = masker.transform(bold_files).transpose()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebfaf3-f78b-4bba-96f8-b15fbd2816e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "# no additional smotthing since contrast maps were already smoothed\n",
    "fwhm = 0 # Set the smoothness parameter (in mm)\n",
    "# this creates a NiftiMasker class, if mask_img is not prvided, will compute the mask in the fit step\n",
    "# mask_img needs to be Niimg-like object so it cannot be the array.# rerun!\n",
    "masker1 = NiftiMasker(smoothing_fwhm=fwhm, mask_img=mask_final_img1).fit()\n",
    "data1 = masker1.transform(bold_files1).transpose()\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e91c4-6c49-40bc-89df-3e61c95ee0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = np.mean(data, 1)\n",
    "print('mean of data_mean:', np.mean(data_mean), 'max of data_mean:', np.max(data_mean), \n",
    "      'min of data_mean:', np.min(data_mean))\n",
    "# masker.inverse_transform: Transform the 2D data matrix back to an image in brain space.\n",
    "## This step only performs spatial unmasking, without inverting any additional processing performed by transform, such as temporal filtering or smoothing.\n",
    "## using this unmasked version only for plotting. the analysis was done on maksed data. \n",
    "## get_data: Get the image data as a numpy.ndarray.\n",
    "data_mean_3d = get_data(masker.inverse_transform(data_mean))\n",
    "\n",
    "\n",
    "print(\"number of voxels in the mask:\", np.prod(get_data(mask_final_img).shape), 'from shape:', get_data(mask_final_img).shape)\n",
    "print(\"number of voxels being 1 in the mask:\", np.sum(get_data(mask_final_img)))\n",
    "\n",
    "# sanity check \n",
    "# raw 3D image has the largest shape\n",
    "print(\"number of voxels in raw contrast image:\", np.prod(get_data(bold_files[0]).shape), 'from shape:', get_data(bold_files[0]).shape)\n",
    "# this is 3d unmasked(with inverse transform), so it has voxels outside the mask and has the same shape as the mask\n",
    "print(\"number of voxels in unmasked data_mean_3d:\", np.prod(data_mean_3d.shape), 'from shape:', data_mean_3d.shape)\n",
    "# this is 1d masked data mean, so it only has voxels inside the mask\n",
    "print(\"number of voxels in masked data_mean:\", np.prod(data_mean.shape))\n",
    "plt.imshow(data_mean_3d[:,:,23])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d8a0f3-b710-414e-bbe9-9a94f755d32d",
   "metadata": {},
   "source": [
    "# SCB construction \n",
    "\n",
    "Now construct SCB with t-bootstrap with rademacher multilpliers. This is done on the masked data of shape (228433*77). \n",
    "\n",
    "From the  3D contrast maps -> sample without replacement to get 20 subjects(this is a subsample)  -> construct SCB \r\n",
    "repeat above 1000 times to calculate the simultaneous covera ratege (the truth is all 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35396ecd-7101-427d-86b3-919c0e78dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update\n",
    "def get_subsample(data, subsample_size=20):\n",
    "    dim = data.shape\n",
    "    n_subj = dim[-1]\n",
    "    data_out = data[..., np.random.choice(n_subj, subsample_size, replace=False)]\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83624157-985f-4c81-8f3f-bfbfc1a5e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# with a large subsample size, there is more dependence \n",
    "setting_df_resting = pd.DataFrame({'subsample_size': [10,20,30,40,50]})\n",
    "print(setting_df_resting)\n",
    "method_df_resting =  pd.DataFrame(product(['res'], ['multiplier'], ['t'], ['r']), columns=['boot_data_type', 'boot_type', 'standardize', 'multiplier'])\n",
    "print(method_df_resting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a7ac0-8b2d-4ddd-bf45-dcd745751110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimuInf.simulation import scb_cover_rate_multiple\n",
    "scb_cover_rate_multiple(setting_df_resting, method_df_resting,\n",
    "                              data_in = data, \n",
    "                      m_sim=10, alpha=0.05,\n",
    "                      m_boots=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43d0a1-0767-4ceb-92d4-c5587a5e8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "resting_result = scb_cover_rate_multiple(setting_df_resting, method_df_resting,\n",
    "                              data_in = data, \n",
    "                      m_sim=1000, alpha=0.05,\n",
    "                      m_boots=1000)\n",
    "#joblib.dump(resting_result, 'results/resting_result_boxcar10_smoothing_4mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f79dd-bd6a-4a1b-a4b0-73935f41b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resting_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08442a4-d23d-4878-a0dd-1d9c56480cb7",
   "metadata": {},
   "source": [
    "# Confidence set validation\n",
    "\n",
    "Now get the simultaneous coverage rate for different levels of c. Based on the theory, inverting the SCB gives valid inference for all c, here, with a finite number of c, the simultaneous coverage rate should be larger. \n",
    "We use the signal from \n",
    "https://github.com/sjdavenport/StatBrainz/tree/main/BrainImages/Volume/fullmean.nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0699d1-b452-49a0-b3a1-8f25cd5fe54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sim_mu_path = os.path.join(os.getcwd(),'data','fullmean.nii')\n",
    "data_sim_mu_raw = get_data(data_sim_mu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85747b38-b780-4c3b-a9f4-42c8e2dba3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sim_mu_raw.shape)\n",
    "# there are nan values \n",
    "print(np.max(data_sim_mu_raw), np.min(data_sim_mu_raw))\n",
    "print(np.sum(np.isnan(data_sim_mu_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5fe35-307d-40b0-bc7f-272ec0640834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the background black\n",
    "plot_img(data_sim_mu_path, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9761e9-2b8d-4c11-b52c-eea8b14d13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform(imgs, counfounds=None, sample_mask=None): apply mask, spatial and temporal preprocessing. \n",
    "# Note, transfrom() also changes the size of the image to match the size of the mask, which is smaller\n",
    "## bold files here already are temporally processed \n",
    "data_sim_mu = masker.transform(data_sim_mu_path).transpose()\n",
    "print(data_sim_mu.shape)\n",
    "\n",
    "# create new data: resting state + mean \n",
    "data_sim = data + data_sim_mu\n",
    "print(data_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974143d-c40b-4650-9848-9b3dcb8487af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform(imgs, counfounds=None, sample_mask=None): apply mask, spatial and temporal preprocessing. \n",
    "# Note, transfrom() also changes the size of the image to match the size of the mask, which is smaller\n",
    "## bold files here already are temporally processed \n",
    "data_sim_mu1 = masker1.transform(data_sim_mu_path).transpose()\n",
    "print(data_sim_mu1.shape)\n",
    "\n",
    "# create new data: resting state + mean \n",
    "data_sim1 = data1 + data_sim_mu1\n",
    "print(data_sim1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a411e6-490e-454a-8025-9f8a01c07e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimuInf.scb import confband\n",
    "from SimuInf.confset import confset\n",
    "from SimuInf.plotting import confset_plot, ls_plot\n",
    "from SimuInf.simulation import scb_cover_rate_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1f9e9-0671-4ba5-b56d-52e2aa9d3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct confidence sets based on a list of thresholds\n",
    "# should not round the level c to avoid repeats \n",
    "thresholds_ls = [np.linspace(-20, 20, num=n_threshold) for n_threshold in [5,10,50,100,1000]]\n",
    "print(thresholds_ls[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12826e3-79b1-4824-96ad-892669b5d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = scb_cover_rate_multiple(setting_df_resting.iloc[:1], method_df_resting,\n",
    "                              data_in = data_sim1, \n",
    "                              mu = data_sim_mu1.reshape(-1),\n",
    "                      m_sim=10, alpha=0.05,\n",
    "                      m_boots=10, thresholds_ls = [np.linspace(-20, 20, num=n_threshold) for n_threshold in [2000]])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5420a2-6e84-4178-90bf-b8ef53fe62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scb_cover_rate_multiple(setting_df_resting.iloc[:1], method_df_resting,\n",
    "                              data_in = data_sim, \n",
    "                              mu = data_sim_mu.reshape(-1),\n",
    "                      m_sim=10, alpha=0.05,\n",
    "                      m_boots=10, thresholds_ls = [np.linspace(-20, 20, num=n_threshold) for n_threshold in [2000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ebf8b-c269-4016-b7fa-ae1d0a7b2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confset_result = scb_cover_rate_multiple(setting_df_resting.iloc[1:], method_df_resting,\n",
    "                              data_in = data_sim, \n",
    "                              mu = data_sim_mu.reshape(-1),\n",
    "                      m_sim=1000, alpha=0.05,\n",
    "                      m_boots=1000, thresholds_ls = thresholds_ls)\n",
    "joblib.dump(confset_result, 'results/scb_confset_result2to5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97d788-5ae4-4e9f-a926-5d10a4545a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confset_result = scb_cover_rate_multiple(setting_df_resting, method_df_resting,\n",
    "                              data_in = data_sim1, \n",
    "                              mu = data_sim_mu1.reshape(-1),\n",
    "                      m_sim=1000, alpha=0.05,\n",
    "                      m_boots=1000, thresholds_ls = thresholds_ls)\n",
    "joblib.dump(confset_result, 'results/scb_confset_result_E3_1to5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b58ab-07b4-4393-a1ad-fe71d2884d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confset1 = joblib.load('results/scb_confset_result1')\n",
    "confset2to5 = joblib.load('results/scb_confset_result2to5')\n",
    "# need to add a column of design E3 and Block\n",
    "confset_all = pd.concat([confset1.assign(data='block'), confset2to5.assign(data='block'), confset_result.assign(data='event')], ignore_index=True)\n",
    "print(confset_all)\n",
    "confset_all.to_excel(\"confset_all.xlsx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
